{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d99ad2-5012-417e-aaf6-971eb96e439a",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb6c49f-51e0-4532-8ab7-8fc2ff0ad4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de l'image:  (1116, 1280, 3)\n",
      "Le fichier est chargé.\n",
      "1 visages detectés dans l'image.\n",
      "C'est tout bon!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image = cv2.imread(\"../data/girl.jpg\")\n",
    "print(\"Dimensions de l'image: \",image.shape)\n",
    "\n",
    "# on convertit l'image en noir et blanc\n",
    "# l'algorithme que nous allons utilisé a besoin de ce pretraitement\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# on a besoin de ce fichier on ne fait ici\n",
    "# que la prédiction, pas le training \n",
    "#https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "# on charge notre modèle\n",
    "face_cascade = cv2.CascadeClassifier(\"../pretrained_models/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# on verifie que le modèle a bien été chargée\n",
    "if face_cascade.empty()==True:\n",
    "\tprint(\"Le fichier n'est pas chargé: \", face_cascade.empty())\n",
    "else:\n",
    "\tprint(\"Le fichier est chargé.\")\n",
    "\n",
    "# On cherche tous les visages disponibles dans l'image\n",
    "faces = face_cascade.detectMultiScale(image_gray, 1.1, 5)\n",
    "# on écrit dans la console le nombre de visages que  l'algorithme a détecté\n",
    "print(f\"{len(faces)} visages detectés dans l'image.\")\n",
    "\n",
    "# on dessine un rectangle autour de chaque visage\n",
    "for x, y, width, height in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + width, y + height), color=(255, 0, 0), thickness=2)\n",
    "\n",
    "print (\"C'est tout bon!\")\n",
    "\n",
    "# on sauvegarde l'image\n",
    "cv2.imwrite(\"../data/new.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48013522-3374-48d5-ae64-86a99d3690eb",
   "metadata": {},
   "source": [
    "Vous avez remarqué que l'on prétraite l'image en la mettant en noir et blanc. Pourquoi?Réduction de la complexité : La conversion de l'image en noir et blanc réduit la complexité de l'image en supprimant les informations de couleur. Cela permet de simplifier le traitement ultérieur de l'image et de réduire les calculs nécessaires pour détecter les caractéristiques du visage.\n",
    "\n",
    "Amélioration du contraste : La conversion en noir et blanc peut améliorer le contraste de l'image, ce qui facilite la détection des contours et des caractéristiques du visage. Les variations de couleurs peuvent parfois rendre la détection des motifs plus difficile, tandis que le noir et blanc permet de mettre davantage l'accent sur les différences de luminosité.\n",
    "\n",
    "Standardisation des données : les modèles Haarcascade sont généralement entraînés sur des images en noir et blanc, donc ils ne seront performants que sur des images similaires.Petite note: La conversion en noir et blanc n'est pas une étape obligatoire dans tous les cas de reconnaissance faciale. Elle dépend du modèle utilisé et des spécificités de la tâche de reconnaissance. Dans certains cas, il peut être préférable de conserver les informations de couleur pour des analyses plus avancées ou des applications spécifiques. Mais dans ces cas là on utilisera généralement des réseaux de neurones (deep learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4fb77-3000-4d1b-8243-79a27a3ee999",
   "metadata": {},
   "source": [
    "# Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f31ac1c-09d8-4e95-9b89-98c950e68dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# initialiser notre webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "# charger notre modele, mettez le bon chemin\n",
    "face_cascade = cv2.CascadeClassifier(\"../pretrained_models/haarcascade_frontalface_alt2.xml\")\n",
    "#print(os.getcwd())\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while True:\n",
    "    # lire notre frame (image)\n",
    "    _, image = cap.read()\n",
    "    # convertir l'image en noir et blanc\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # detecter tous les visages présents\n",
    "    faces = face_cascade.detectMultiScale(image_gray, 1.1, 5)\n",
    "    # tracer un rectangle pour chaque visage\n",
    "    for x, y, width, height in faces:\n",
    "        cv2.rectangle(image, (x, y), (x + width, y + height), color=(255, 0, 0), thickness=2)\n",
    "    \n",
    "    # ecrire sur l'image le nombre de visages detectes\n",
    "    cv2.putText(image,'Visage detectes : ' + str(len(faces)),(40, 40), font, 1,(255,0,0),2)\n",
    "    cv2.imshow(\"image\", image)\n",
    "   # afficher le rendu de la webcam et appuyez sur 'q' pour quitter\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# detruire toutes les fenetres après avoir quitté le programme\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24d538-5f6d-4813-9567-33529d5e0054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
